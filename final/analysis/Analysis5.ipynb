{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv                  #Importing all the packages needed\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root ='..\\\\data'                                      #Relative path where dataset is stored\n",
    "stop_words = stopwords.words('english')               #Get all the english language stop words \n",
    "l = pd.read_csv(os.path.join(root,'listings.csv'))    #Get the dataset and store it in dataframe\n",
    "r = pd.read_csv(os.path.join(root,'reviews.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile = open('analysis5.csv', 'w', encoding='utf-8')     #Create the csv file to show the output\n",
    "wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "wr.writerow(('ListingId','Neighbourhood','SummaryByHost','CommentByVisitor','Similarity','Degree'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def totalWords(sent):                                     #Function to remove stop words and numbers from sentences\n",
    "    words=[]\n",
    "    for word in re.sub(\"[^\\w]\", \" \",  sent).split():\n",
    "        if word.lower() not in stop_words and word.isalpha():\n",
    "            words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getNeighbourhood(id):                                #Function to get neighbourhood name from listing id\n",
    "    loc = l.loc[l['id']== id,'neighbourhood'].iloc[0]\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listSummary(id):                                    #Function to get all words from summary removing stop words\n",
    "    summary=l[l['id']== id].summary.tolist()\n",
    "    words=totalWords(summary[0])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listComment(id):                                    #Function to get all words from comments removing stop words\n",
    "    words=[]\n",
    "    comment=r[r['listing_id']== id].comments.tolist()\n",
    "    if comment:\n",
    "        words=totalWords(comment[0])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match(summary,comment):                             #Match both the comment and summary to get the similarity\n",
    "    match=[]\n",
    "    for word in summary:\n",
    "        for synset in wordnet.synsets(word):\n",
    "            for lemma in synset.lemma_names():\n",
    "                if lemma in comment:\n",
    "                     match.append(lemma)\n",
    "    return list(set(match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r=r[r['comments'].notnull()]                            #Remove all the rows from dataset where there are no comment\n",
    "l=l[l['summary'].notnull()]                             #Remove all the rows from dataset where there are no summary\n",
    "similarity=0\n",
    "for id in l['id']:                                      #Get all the listing ids which are present in both listings and reviews dataset\n",
    "    if id in r['listing_id']: \n",
    "        location=getNeighbourhood(id)\n",
    "        summary=listSummary(id)                         #Get all the summary words \n",
    "        comment=listComment(id)                         #Get all the comment words \n",
    "        degree=match(summary,comment)                   #Get the degree of similarity\n",
    "        wr.writerow((id,location,summary,comment,degree,len(degree)))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
