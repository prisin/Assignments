{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question1\n",
    "\n",
    "- Analysis of Enron Scandal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from email.parser import Parser\n",
    "import nltk\n",
    "root ='..\\\\data\\\\enron'                   #Path to retrive email data\n",
    "\n",
    "to_list = []                                   #Initializing list to store to,from of emails\n",
    "from_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for directory, subdirectory, filenames in  os.walk(root):   #checking the files and dir from root path\n",
    "    for filename in filenames:\n",
    "        with open(os.path.join(directory, filename), \"r\") as f:\n",
    "            data = f.read()                                 #reading data from files\n",
    "          \n",
    "        email = Parser().parsestr(data)                     #parsing email data\n",
    "        \n",
    "        email_to=email['to']                                #retrieving all the contacts emails sent to people\n",
    "        if email_to:\n",
    "            for m in email_to.split(','):\n",
    "                    match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', m)\n",
    "                    if match:   \n",
    "                        to_list.append(match.group(0))\n",
    "        \n",
    "        from_list.append(email['from'])                     #retrieving all the contacts emails sent from people\n",
    " \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"to_email.txt\", \"w\") as f:\n",
    "    for to_email in to_list:\n",
    "        if to_email:\n",
    "            f.write(to_email)\n",
    "            f.write(\",\")\n",
    "f.close()\n",
    "\n",
    "with open(\"from_email.txt\", \"w\") as f:\n",
    "    for from_email in from_list:\n",
    "        if from_email:\n",
    "            f.write(from_email)\n",
    "            f.write(\",\")        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most emails sent to: \n",
      "\n",
      "[('richard.shapiro@enron.com', 15149), ('jeff.dasovich@enron.com', 14207), ('tana.jones@enron.com', 12828), ('steven.kean@enron.com', 12754), ('sara.shackleton@enron.com', 11433), ('james.steffes@enron.com', 10347), ('mark.taylor@enron.com', 9787), ('pete.davis@enron.com', 9281), ('susan.mara@enron.com', 9064), ('paul.kaufman@enron.com', 8522)]\n",
      "\n",
      "Most emails came from: \n",
      "\n",
      "[('kay.mann@enron.com', 16735), ('vince.kaminski@enron.com', 14368), ('jeff.dasovich@enron.com', 11411), ('pete.davis@enron.com', 9149), ('chris.germany@enron.com', 8801), ('sara.shackleton@enron.com', 8777), ('enron.announcements@enron.com', 8587), ('tana.jones@enron.com', 8490), ('steven.kean@enron.com', 6759), ('kate.symes@enron.com', 5438)]\n"
     ]
    }
   ],
   "source": [
    "import collections                                        #Finding the max emails sent to and from contacts\n",
    " \n",
    "with open(\"to_email.txt\", \"r\") as f:    #Reading the email to file and extracting data\n",
    "    data = f.read()\n",
    "\n",
    "words= data.split(\",\")            \n",
    "print(\"\\nMost emails sent to: \\n\")\n",
    "print(collections.Counter(words).most_common(10))\n",
    "f.close()\n",
    "\n",
    "with open(\"from_email.txt\", \"r\") as f:    #Reading the email from file and extracting data\n",
    "    data = f.read()\n",
    "\n",
    "words= data.split(\",\")            \n",
    "print(\"\\nMost emails came from: \\n\")\n",
    "print(collections.Counter(words).most_common(10))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analysis-1: Richard Shapira got the max emails.He was the senior vice president of Enron.\n",
    "#             He had updates about all happenings in company.\n",
    "#             Most emails sent from kay mann.She is the Senior Counsel in Enron and she always keep everyone updated.   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "email_body = []                                             #Initializing list to store body of emails\n",
    "\n",
    "for directory, subdirectory, filenames in  os.walk(root):   #iterating over the dir of kenneth Lay emails-founder of Enron\n",
    "    if 'lay-k' in directory:\n",
    "        for filename in filenames:\n",
    "            with open(os.path.join(directory, filename), \"r\") as f:\n",
    "                 data = f.read()                                 #reading data from files\n",
    "          \n",
    "            email = Parser().parsestr(data)                     #parsing email data\n",
    "            \n",
    "            if email.is_multipart():                            #retrieving all the emails body \n",
    "                    for payload in b.get_payload():\n",
    "                        email_body.append(payload.get_payload())\n",
    "            else:\n",
    "                    email_body.append(email.get_payload())\n",
    "            \n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"email_body.txt\", \"w\") as f:     #storing all the data from list to file\n",
    "    for content in email_body:\n",
    "        if content:\n",
    "            f.write(content)\n",
    "            f.write(\"\\n\")   \n",
    "f.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Enron', 'company', 'employees', 'energy', 'made', 'would', 'California', 'Lay', 'consumers', 'Ken', 'http', 'Please', 'million', 'stock', 'pay', 'funds', 'retirement', 'bills', 'bankruptcy', 'millions', 'donate', 'declared', 'year', 'New', 'ENRON', 'help', 'information', 'know', 'last', 'time', 'well', 'many', 'please', 'new', 'provide', 'like', 'business', 'meeting', 'Houston', 'York', 'keep', 'ECT', 'also', 'efforts', 'one', 'money', 'state', 'set', 'Sincerely', 'call', 'October', 'result', 'largest', 'may', 'plans', 'Times', 'Communications', 'writing', 'lost', 'benefit', 'Fund', 'dollars', 'reported', 'Americans', 'unable', 'Employee', 'utility', 'lives', 'crisis', 'selling', 'worth', 'thousands', 'sold', 'buying', 'basic', 'profit', 'afford', 'relief', 'savings', 'Transition', 'aggressively', 'hurt', 'financially', 'Indeed', 'devastated', 'urge', 'urging', 'repair', 'Compaq', 'underhanded', 'netted', 'wiped', 'REACH', 'dealings', 'could', 'bankrupt', 'pocketbooks', 'astronomical', 'Energy', 'contact']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')           \n",
    "mail_words = ['From', 'Sent', 'To', 'Cc', 'Subject']\n",
    "freqWords={}\n",
    "\n",
    "with open(\"email_body.txt\", \"r\") as f:    #Reading the email body file and extracting data\n",
    "    data = f.read()\n",
    "\n",
    "words= word_tokenize(data)                                 #spliting each word of data to list\n",
    "\n",
    "for word in words:                                       #Iterating over words \n",
    "        if word not in mail_words and len(word) > 2: #checking if not in mail words defined abve and length not less than 2\n",
    "            fiterWord=word.lower()\n",
    "            if fiterWord.isalpha() and fiterWord not in stop_words: #checking if word is alphabet and not stopwords\n",
    "                if word in freqWords:   #Adding all word counts in a dictionary to count frequency of same words\n",
    "                    freqWords[word] +=1\n",
    "                else:\n",
    "                    freqWords[word] =1\n",
    "                \n",
    "top100 = sorted(freqWords, key = freqWords.get, reverse = True)[:100]  #Sorting all words to get top 100 words used\n",
    "print(top100)   #Printing the top 100 words\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analysis-2: It is about Enron company related with 'energy'. \n",
    "#     It talks about 'millions' and 'bankrupty' many times.\n",
    "#     In emails it mainly talks about buisness 'meeting'.Lay attends lot of meetings.\n",
    "\n",
    "# Analysis-3:It talks about 'california' many times(some history there)\n",
    "#     It talks about 'buying','selling' and 'profit'.some buying selling was always going on in company.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
